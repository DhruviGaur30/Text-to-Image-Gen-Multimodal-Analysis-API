---
# ğŸ§  Multimodal Text-to-Image Generation and Analysis System

A modular, production-style **multimodal AI pipeline** that integrates **text-to-image generation**, **image understanding**, **region-based analysis**, and **visualization** into a single unified API.
This project demonstrates how multiple state-of-the-art AI models can be orchestrated together in a clean, extensible backend system.

---

## ğŸš€ Project Overview

This system integrates **three complementary AI models**:

| Model                 | Purpose                                 |
| --------------------- | --------------------------------------- |
| **Stable Diffusion**  | Text â†’ Image generation                 |
| **CLIP**              | Global image-text semantic analysis     |
| **Region-based CLIP** | Spatial understanding of image regions  |
| **SAM (Placeholder)** | Image segmentation pipeline integration |

The pipeline supports:

* Generating images from text prompts
* Uploading images for semantic analysis
* Region-wise CLIP scoring
* Segmentation-aware visualization
* UI-ready base64 visual outputs

---

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ api/            # FastAPI routes
â”œâ”€â”€ core/           # Global config & logging
â”œâ”€â”€ models/         # Stable Diffusion, CLIP, SAM
â”œâ”€â”€ pipeline/       # Orchestration logic
â”œâ”€â”€ utils/          # Encoding, file handling, visualization
â”œâ”€â”€ tests/          # Pytest test suite
â”œâ”€â”€ outputs/        # Generated & analyzed images
â””â”€â”€ main.py         # Application entrypoint
```

Each component is **loosely coupled**, making the system easy to extend or replace individual models.

---

## ğŸ”Œ API Endpoints

### ğŸ”¹ `POST /generate`

Generate an image from a text prompt.

**Input**

```json
{
  "prompt": "a cute cat astronaut floating in space"
}
```

**Output**

```json
{
  "image_path": "outputs/generated_20260119_002712.png"
}
```

---

### ğŸ”¹ `POST /analyze`

Upload an image for multimodal analysis.

**Input**

* `multipart/form-data`
* Image file

**Output**

```json
{
  "image_path": "outputs/uploaded_20260119_111911.png",
  "clip_analysis": {...},
  "region_clip_analysis": [...],
  "segmentation": {...},
  "visualization_base64": "<base64 string>"
}
```

---

### ğŸ”¹ `GET /`

Health check endpoint.

---

## âœ… Completed Features (Required Criteria)

âœ” **Successful integration of all three models**

âœ” **Stable Diffusion text-to-image generation**

âœ” **CLIP-based semantic analysis**

âœ” **Region-based CLIP scoring**

âœ” **Segmentation pipeline integration (SAM placeholder)**

âœ” **Clean API with FastAPI & OpenAPI documentation**

âœ” **Modular, production-style code organization**

âœ” **Basic error handling with logging**

âœ” **Essential automated tests (pytest)**


---

## â­ Implemented Bonus Features

* Region-aware CLIP analysis
* Visualization overlays
* UI-ready base64 image streaming
* Separation of inference, utilities, and orchestration
* CPU/GPU compatibility handling

---

## ğŸ§ª Testing

Run tests from project root:

```bash
python -m pytest
```

Included tests:

* API health check
* Image generation endpoint
* Image analysis endpoint

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the API

```bash
uvicorn app.main:app --reload
```

### 3ï¸âƒ£ Open API Docs

```
http://127.0.0.1:8000/docs
```

---

## ğŸ–¥ï¸ Hardware Support

| Mode       | Supported       |
| ---------- | --------------- |
| CPU        | âœ… Yes           |
| GPU (CUDA) | âœ… Auto-detected |

The system automatically falls back to CPU if CUDA is unavailable.

---

## ğŸ”® Future Improvements (Planned)

The following enhancements are **intentionally left for future work**:

### ğŸ”¹ Model Improvements

* Replace SAM placeholder with real SAM weights
* Dynamic region proposals instead of grid-based splitting
* CLIP embedding caching for performance

### ğŸ”¹ Visualization Enhancements

* Confidence-colored bounding boxes
* Per-region top-label overlays
* Interactive front-end (optional)

### ğŸ”¹ Engineering Enhancements

* Dockerized deployment (CPU & GPU images)
* Async inference for scalability
* Model warm-up and lazy loading
* Rate limiting & request validation

### ğŸ”¹ Testing & Reliability

* Stress tests for large images
* Mock-based unit tests
* Advanced exception categorization

---

## ğŸ§  Design Philosophy

This project prioritizes:

* **Clarity over over-engineering**
* **Correct integration over raw model performance**
* **Extensibility over hard-coding**

All architectural decisions were made to reflect **real-world production systems**, not notebooks or demo scripts.

---
